{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46db8b1c-069b-4653-a91b-d71b444937ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab636a13-a89a-4865-a9c9-97903d1aef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))  # Fix missing stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ef92b5-972e-4d09-ab17-a2690c9d2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello, how are you doing today?\n",
      "Processed: hello today\n",
      "\n",
      "Preprocessed Intents:\n",
      "greeting: ['hello', 'hi', 'hey', 'good morning']\n",
      "farewell: ['bye', 'goodbye', 'see', 'take care']\n",
      "how_are_you: ['', '', 'okay']\n",
      "default: []\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Test preprocessing\n",
    "sample_text = \"Hello, how are you doing today?\"\n",
    "processed_text = preprocess_text(sample_text)\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Processed: {processed_text}\")\n",
    "\n",
    "# Preprocess all patterns in intents\n",
    "preprocessed_intents = {}\n",
    "for intent, data in intents.items():\n",
    "    preprocessed_intents[intent] = {\n",
    "        \"patterns\": [preprocess_text(pattern) for pattern in data[\"patterns\"]],\n",
    "        \"responses\": data[\"responses\"]\n",
    "    }\n",
    "\n",
    "# Display preprocessed intents\n",
    "print(\"\\nPreprocessed Intents:\")\n",
    "for intent, data in preprocessed_intents.items():\n",
    "    print(f\"{intent}: {data['patterns']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fab17dff-52d1-491f-b77d-4b9283e88481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intents: maps user phrases to chatbot responses for training and replies.\n",
    "intents = {\n",
    "    \"greeting\": {\n",
    "        \"patterns\": [\"hello\", \"hi\", \"hey\", \"good morning\"],\n",
    "        \"responses\": [\"Hi there!\", \"Hello!\", \"Hey! How can I help?\", \"Good morning!\"]\n",
    "    },\n",
    "    \"farewell\": {\n",
    "        \"patterns\": [\"bye\", \"goodbye\", \"see you\", \"take care\"],\n",
    "        \"responses\": [\"Goodbye!\", \"See you later!\", \"Take care!\"]\n",
    "    },\n",
    "    \"how_are_you\": {\n",
    "        \"patterns\": [\"how are you\", \"how you doing\", \"are you okay\"],\n",
    "        \"responses\": [\"I'm just a chatbot, but I'm doing great!\", \"All good here, thanks!\"]\n",
    "    },\n",
    "    \"default\": {\n",
    "        \"patterns\": [],\n",
    "        \"responses\": [\"Sorry, I don’t understand.\", \"Can you rephrase that?\"]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2552a10a-3a9a-4536-a5b1-2777cbcdb110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Training Data: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentences: ['hello', 'hi', 'hey', 'good morning', 'bye', 'goodbye', 'see you', 'take care', 'how are you', 'how you doing', 'are you okay']\n",
      "Labels: ['greeting', 'greeting', 'greeting', 'greeting', 'farewell', 'farewell', 'farewell', 'farewell', 'how_are_you', 'how_are_you', 'how_are_you']\n",
      "\n",
      "Testing ML-Based Chatbot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ML Inputs: 100%|█████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 973.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi there | Bot: Hello!\n",
      "User: goodbye | Bot: Take care!\n",
      "User: how you doing | Bot: All good here, thanks!\n",
      "User: what's this | Bot: Hi there!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Prepare training data from intents\n",
    "training_sentences = []\n",
    "labels = []\n",
    "\n",
    "# Use tqdm to track data preparation\n",
    "for intent, data in tqdm(intents.items(), desc=\"Preparing Training Data\"):\n",
    "    if intent != \"default\":  # Skip default intent for training\n",
    "        for pattern in data[\"patterns\"]:\n",
    "            training_sentences.append(pattern)\n",
    "            labels.append(intent)\n",
    "\n",
    "# Print prepared data\n",
    "print(f\"Training Sentences: {training_sentences}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(training_sentences)\n",
    "\n",
    "# Train SVM model\n",
    "model = SVC(kernel=\"linear\", probability=True)\n",
    "model.fit(X, labels)\n",
    "\n",
    "# ML-based chatbot function\n",
    "def ml_chatbot(text):\n",
    "    # Vectorize the input\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    \n",
    "    # Predict intent\n",
    "    predicted_intent = model.predict(text_vector)[0]\n",
    "    \n",
    "    # Return a random response from the predicted intent\n",
    "    return random.choice(intents[predicted_intent][\"responses\"])\n",
    "\n",
    "# Test the ML chatbot with tqdm\n",
    "test_inputs = [\"hi there\", \"goodbye\", \"how you doing\", \"what's this\"]\n",
    "print(\"\\nTesting ML-Based Chatbot:\")\n",
    "for input_text in tqdm(test_inputs, desc=\"Processing ML Inputs\"):\n",
    "    response = ml_chatbot(input_text)\n",
    "    print(f\"User: {input_text} | Bot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf5409-9316-489c-a414-b2d45d8e8fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfadb5b-6d0f-4a0e-95eb-d3bf796a4368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f38d0-414a-4fc4-8b9d-509e5d40af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
